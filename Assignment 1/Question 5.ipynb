{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Question 5: \n",
    "- Use Gutenberg and Web_text data. Find out what are the top 5 words that Shakespeare used but we do not use in currently.\n",
    "- Take top 50 words from Shakespeare (all 3 books) and top 50 from Web_text (all the records).\n",
    "- Remove punctuation and stop words.\n",
    "- Remove the words we still use today, and get the unused list. Show the top 5 elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import webtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding out top 5 unused word list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 words of shakesspeare \n",
      " [('haue', 402), ('Ham', 337), ('Lord', 293), ('shall', 259), ('thou', 253), ('King', 227), ('Enter', 225), ('Caesar', 188), ('vs', 178), ('thy', 175), ('thee', 174), ('good', 164), ('know', 163), ('Brutus', 161), ('Bru', 153), ('come', 151), ('Macb', 137), ('like', 136), ('selfe', 134), ('would', 133), ('man', 126), ('well', 125), ('vpon', 119), ('may', 117), ('must', 116), ('hath', 115), ('let', 111), ('say', 110), ('Cassi', 107), ('Ile', 106), ('yet', 104), ('time', 103), ('see', 101), ('one', 101), ('make', 101), ('speake', 100), ('Hamlet', 99), ('Hor', 95), ('heere', 93), ('vp', 90), ('Sir', 89), ('doe', 88), ('mine', 85), ('Cassius', 85), ('much', 83), ('Let', 82), ('Come', 81), ('loue', 80), ('men', 80), ('Oh', 80)] \n",
      "\n",
      "Top 50 words of web_text \n",
      " [('Girl', 1752), ('Guy', 1658), ('like', 1527), ('girl', 1185), (\"I'm\", 1116), (\"don't\", 1078), ('guy', 1069), ('know', 979), ('get', 776), ('-', 748), ('page', 690), ('Yeah', 688), ('Woman', 639), ('Oh', 600), ('one', 597), ('window', 584), (\"doesn't\", 583), ('cell', 577), ('Firefox', 577), ('Teen', 550), ('open', 522), ('work', 514), ('Chick', 514), (\"it's\", 505), ('Man', 501), ('man', 497), ('new', 492), ('go', 480), ('think', 476), ('good', 476), ('want', 470), ('bar', 468), ('menu', 452), (\"It's\", 451), ('going', 438), (\"can't\", 435), ('boy', 423), ('tab', 415), ('Firebird', 412), ('right', 409), ('got', 401), ('time', 395), ('really', 388), ('Well', 386), ('button', 357), ('lady', 353), ('toolbar', 348), ('back', 347), ('would', 344), ('browser', 333)] \n",
      "\n",
      "Top 5 unused words are: \n",
      " ['haue', 'Ham', 'Lord', 'shall', 'thou']\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculateWord(file_name,type):      #making a function for calculating word frequency \n",
    "    dist ={}\n",
    "    demo = []\n",
    "    demo.append(\" \")\n",
    "    newFile=[]\n",
    "    file22 = stopwords.open('english')     # getting all the stopwords in a list demo\n",
    "    for sentence22 in file22:\n",
    "                sentence22=sentence22.strip(\"\\n\")  #striping the newline character from file \n",
    "                demo.append(sentence22)\n",
    "    for x in file_name:                     #checking wheather file is from gutenburg corpus or web text corpus and accorging to \n",
    "                                               # it opening the stream \n",
    "        if type =='shakesspeare': \n",
    "            file1 = gutenberg.open(x)\n",
    "        if type =='web_text':\n",
    "            file1 = webtext.open(x)\n",
    "        for sentence1 in file1 :\n",
    "                sentence1=sentence1.replace(',','')\n",
    "                sentence1=sentence1.replace('*','')\n",
    "                sentence1=sentence1.replace('?','')                # removing all punctuation from the sentences\n",
    "                sentence1=sentence1.replace(')','')\n",
    "                sentence1=sentence1.replace('(','')\n",
    "                sentence1=sentence1.replace(';','')\n",
    "                sentence1=sentence1.replace(':','')\n",
    "                sentence1=sentence1.replace('&','')\n",
    "                sentence1=sentence1.replace('.','')\n",
    "                sentence1=sentence1.replace('#','')\n",
    "                sentence1=sentence1.strip()\n",
    "                sentence1=sentence1.strip(\"\\n\")\n",
    "                sentence1=sentence1.split(\" \")               # spliting the sentence on space so that we will get words \n",
    "\n",
    "                for word in sentence1:\n",
    "                    if (word.lower() not in demo and not word.isdigit()) :\n",
    "                        if word in dist:\n",
    "                            dist[word] = dist[word]+1      # counting the frequency of each word\n",
    "                        else:\n",
    "                            dist[word] = 1\n",
    "    dist.pop('')                                           # removing the initial blank space\n",
    "\n",
    "    sorted_characters = sorted(dist.items(), key=operator.itemgetter(1), reverse = True) # sorting the dict based on frequency\n",
    "    temp=sorted_characters[:50]\n",
    "    print ('Top 50 words of',type,'\\n',sorted_characters[:50],'\\n')\n",
    "    return sorted_characters[:50]                              # returning top 50 words \n",
    "    \n",
    "def main():\n",
    "    file_name = ['shakespeare-caesar.txt','shakespeare-hamlet.txt','shakespeare-macbeth.txt']\n",
    "    sWord=calculateWord(file_name,'shakesspeare')\n",
    "    names1 = webtext.fileids()\n",
    "    wWord=calculateWord(names1,'web_text')\n",
    "    check=[]\n",
    "    for w in wWord:\n",
    "        check.append(w[0])\n",
    "    final=[]\n",
    "    for w in sWord:\n",
    "        if w[0] not in check:                       #copmpairing the ords and finding out unique words by shakespeare\n",
    "            final.append(w[0])\n",
    "    print('Top 5 unused words are: \\n',final[:5])         # printing top 5 words\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
